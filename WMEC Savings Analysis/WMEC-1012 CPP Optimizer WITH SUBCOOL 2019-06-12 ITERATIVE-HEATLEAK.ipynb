{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TST analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\r\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\r\n",
      "Requirement already satisfied: pytool in /opt/conda/lib/python3.7/site-packages (3.15.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pytool) (1.12.0)\r\n",
      "Requirement already satisfied: simplejson>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from pytool) (3.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#General modules including data restructuring and machine learning libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pytz\n",
    "import pytool\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from pulp import *\n",
    "from scipy import stats\n",
    "from scipy import interpolate\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "\n",
    "# System modules\n",
    "import inspect\n",
    "import sys\n",
    "import operator\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Label_generator(list_length):\n",
    "    \n",
    "    Time_labels = []\n",
    "    \n",
    "    for t in range(list_length):\n",
    "        Time_labels+=[\"T\"+str(t+1).zfill(2)]\n",
    "    \n",
    "    return Time_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Event_label_generator(list_length):\n",
    "    \n",
    "    Event_labels = []\n",
    "    \n",
    "    for e in range(list_length*16):\n",
    "        Event_labels+=[\"E\"+str(e+1).zfill(2)]\n",
    "    \n",
    "    return Event_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Timestamp_label_generator(start_date,end_date, tz):\n",
    "    '''\n",
    "    Creates and returns a dataframe of timestamps and time_lables T[i]\n",
    "    '''\n",
    "    Timestamps = pd.date_range(start_date,end_date,freq = '15T', tz = tz).tolist()\n",
    "    #del Timestamps[-1]\n",
    "    \n",
    "    Time_labels = Label_generator(len(Timestamps))\n",
    "    \n",
    "    return pd.DataFrame(OrderedDict((('Time_label',Time_labels),('Timestamp',Timestamps))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Holidays_generator():\n",
    "    \n",
    "    Holidays = USFederalHolidayCalendar().holidays(start = datetime.date(2018, 1, 1),\n",
    "                                               end = datetime.date(2018, 12, 31))[[0, 2, 3, 4, 5, 7, 8, 9]]\n",
    "    \n",
    "    return Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Season(dt):\n",
    "    # Takes in a datetime object and returns the season as outlined by the PG&E E19 plan\n",
    "    \n",
    "    if dt.month >= 6 and dt.month <= 10: # if the day is between May 1 and October 31\n",
    "        return 'Summer' # Mark the day as summer\n",
    "    else:\n",
    "        return 'Winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Period(dt, Holidays):\n",
    "    # Takes in a datetime object (with year, month, day, hour, and minute), the season function, and the Holidays pandas index  \n",
    "    \n",
    "    # returns the time period as either Peak, Mid-Peak, or Off-Peak\n",
    "    \n",
    "    if Season(dt) == 'Summer': # if the month is during the summer\n",
    "        \n",
    "        if (datetime.date(dt.year, dt.month, dt.day) in Holidays) or (dt.isoweekday() >= 6):# If the date is a holiday, it's off-peak\n",
    "            \n",
    "            if (datetime.time(hour =  dt.hour) >= datetime.time(hour = 16) and \n",
    "                datetime.time(hour =  dt.hour) < datetime.time(hour = 21)):\n",
    "                \n",
    "                return 'On-Peak Summer'\n",
    "        \n",
    "            elif (datetime.time(hour =  dt.hour) < datetime.time(hour = 14)):\n",
    "            # If the time is between [2130, 0830) and the day is not a weekend or holiday, it's off-peak\n",
    "                return 'Super Off-Peak Summer'\n",
    "        \n",
    "            else:\n",
    "                return 'Off-Peak Summer'\n",
    "        \n",
    "        else: \n",
    "            if (datetime.time(hour =  dt.hour) >= datetime.time(hour = 16) and \n",
    "                datetime.time(hour =  dt.hour) < datetime.time(hour = 21)):\n",
    "                return 'On-Peak Summer' \n",
    "        \n",
    "            elif (datetime.time(hour =  dt.hour) < datetime.time(hour = 6)):\n",
    "            # If the time is between [2130, 0830) and the day is not a weekend or holiday, it's off-peak\n",
    "                return 'Super Off-Peak Summer'\n",
    "        \n",
    "            else:\n",
    "                return 'Off-Peak Summer'\n",
    "    \n",
    "    # TO DO - Implememt new sdge tariff for winter months\n",
    "    elif Season(dt) == 'Winter': # if the month is during the winter\n",
    "        \n",
    "        if (datetime.date(dt.year, dt.month, dt.day) in Holidays) or (dt.isoweekday() >= 6):# If the date is a holiday, it's off-peak\n",
    "            \n",
    "            if (datetime.time(hour =  dt.hour) >= datetime.time(hour = 16) and \n",
    "                datetime.time(hour =  dt.hour) < datetime.time(hour = 21)):\n",
    "                \n",
    "                return 'On-Peak Winter'\n",
    "        \n",
    "            elif (datetime.time(hour =  dt.hour) < datetime.time(hour = 14)):\n",
    "            # If the time is between [2130, 0830) and the day is not a weekend or holiday, it's off-peak\n",
    "                return 'Super Off-Peak Winter'\n",
    "        \n",
    "            else:\n",
    "                return 'Off-Peak Winter'\n",
    "        \n",
    "        else: \n",
    "            if (datetime.time(hour =  dt.hour) >= datetime.time(hour = 16) and \n",
    "                datetime.time(hour =  dt.hour) < datetime.time(hour = 21)):\n",
    "                return 'On-Peak Winter' \n",
    "        \n",
    "            elif (datetime.time(hour =  dt.hour) < datetime.time(hour = 6)):\n",
    "            # If the time is between [2130, 0830) and the day is not a weekend or holiday, it's off-peak\n",
    "                return 'Super Off-Peak Winter'\n",
    "            \n",
    "            elif (dt.month in [3,4]) & (datetime.time(hour =  dt.hour) >= datetime.time(hour = 10) and \n",
    "                datetime.time(hour =  dt.hour) < datetime.time(hour = 14)):\n",
    "                \n",
    "                return 'Super Off-Peak Winter'\n",
    "            \n",
    "            else:\n",
    "                return 'Off-Peak Winter'    \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        return 'Error!'\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tariff_generator(start_ts, end_ts, timezone):\n",
    "    \n",
    "    #Define Energy Tariff\n",
    "    energy_periods = ['On-Peak Summer','Off-Peak Summer','Super Off-Peak Summer', 'On-Peak Winter','Off-Peak Winter','Super Off-Peak Winter']\n",
    "    energy_rates = [0.140515, 0.119485, 0.098385, 0.125915, 0.113465, 0.099645]\n",
    "    energy_tariff = dict(zip(energy_periods,energy_rates))\n",
    "    \n",
    "    #Generate Holiday schedule\n",
    "    Holidays =  Holidays_generator()\n",
    "    tariff_list = []\n",
    "    \n",
    "    #Generate time labels and datetime range\n",
    "    data = Timestamp_label_generator(start_ts,end_ts, timezone)\n",
    "    \n",
    "    #Loop through each datetime and assign a tariff according to its season, time conditional on whether its a weekend or holiday\n",
    "    for ts in data.Timestamp:\n",
    "        period =  Period(ts,Holidays)\n",
    "        tariff_list.append(energy_tariff[period])\n",
    "    \n",
    "    data = data.assign(energy_tariff = tariff_list)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Demand_charges_generator():\n",
    "    \n",
    "    demand_periods = ['Maximum Peak Demand Summer', 'Maximum Demand Summer',\n",
    "                      'Maximum Peak Demand Winter', 'Maximum Demand Winter']\n",
    "    \n",
    "    demand_rates = [17.42,24.23,16.98,21.34]\n",
    "\n",
    "    return dict(zip(demand_periods,demand_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_generator(data, start_ts, end_ts, timezone):\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    Holidays =  Holidays_generator()\n",
    "    Load_values = data[['Timestamp','building.baseline.power.kW']]\n",
    "    \n",
    "    Timestamp_labels = Timestamp_label_generator(start_ts,end_ts, timezone)\n",
    "\n",
    "    Max_demands_load = {}\n",
    "    periods = []\n",
    "    seasons = []\n",
    "\n",
    "    Load_table = Timestamp_labels.merge(Load_values, on = 'Timestamp')\n",
    "    \n",
    "    Load_table = Load_table.rename(columns = {'building.baseline.power.kW': 'Load_values'})\n",
    "        \n",
    "    for ts in Load_table.Timestamp:\n",
    "        periods.append(Period(ts,Holidays))\n",
    "        seasons.append(Season(ts))\n",
    "    \n",
    "    Load_table = Load_table.assign(Periods = periods)\n",
    "    Load_table = Load_table.assign(Seasons = seasons)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    interp_func = interpolate.interp1d(list(map(lambda d: d.timestamp(),interp_train.Timestamp)), \n",
    "                             interp_train.Load_values, kind = 'linear')\n",
    "\n",
    "    Load_table = Load_table.assign(Load_values = interp_func(list(map(lambda d: d.timestamp(), Load_table.Timestamp))))\n",
    "    '''\n",
    "    Group_object = Load_table.groupby(['Seasons','Periods'])['Load_values'].max()\n",
    "    \n",
    "    if \"Summer\" in seasons:\n",
    "        Max_demands_load['Maximum_Peak_Demand_Summer'] = Group_object['Summer']['On-Peak Summer']\n",
    "        Max_demands_load['Maximum_Demand_Summer'] = Group_object[\"Summer\"].max()\n",
    "    \n",
    "    if \"Winter\" in seasons:\n",
    "        Max_demands_load['Maximum_Peak_Demand_Winter'] = Group_object['Winter']['On-Peak Winter']\n",
    "        Max_demands_load['Maximum_Demand_Winter'] = Group_object[\"Winter\"].max()\n",
    "\n",
    "    return (Load_table, Max_demands_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRS_load(data, start_ts, end_ts, time_labels, timezone):\n",
    "    \n",
    "    #Creating CRS Load\n",
    "    Load_values = data[['Timestamp','crs.baseline.power.kW']]\n",
    "    \n",
    "    Timestamp_labels = Timestamp_label_generator(start_ts,end_ts, timezone)\n",
    "\n",
    "    Load_table = Timestamp_labels.merge(Load_values, on = 'Timestamp')\n",
    "    Load_table = Load_table.rename(columns = {'crs.baseline.power.kW': 'CRS_Load_values'})\n",
    "    \n",
    "    '''\n",
    "    interp_func = interpolate.interp1d(list(map(lambda d: d.timestamp(),interp_train.Timestamp)), \n",
    "                             interp_train.CRS_Load_values, kind = 'linear')\n",
    "\n",
    "    Load_table = Load_table.assign(CRS_Load_values = interp_func(list(map(lambda d: d.timestamp(), Load_table.Timestamp))))\n",
    "    '''\n",
    "    Load_table = Load_table.assign(temperature = data.temperature)\n",
    "    \n",
    "    return dict(zip(time_labels, Load_table['CRS_Load_values'])), Load_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Limits(data, MCL, sensible_subcool):\n",
    "    \n",
    "    #Convert oat_c from F to C\n",
    "    df = data.assign(oat_c = data.temperature.apply(lambda d: (d - 32)*5/9))\n",
    "\n",
    "    # Isentropic efficiency:\n",
    "    Isentropic_eff = lambda t: -0.0001093*t*t + 0.006782*t + 0.5704\n",
    "    \n",
    "    # Max Rack Load fit:\n",
    "    MRC = lambda t: -0.001532*t*t - 4.87*t + 424.1\n",
    "    \n",
    "    # Charge COP fit for RT = 1\n",
    "    CHG_COP_rt1 = lambda t: 0.00011286509783997348*t*t -0.02835906022493903*t + 2.0938080794453984\n",
    "    \n",
    "    # Calculate Charge limits:\n",
    "    \n",
    "    total_rack_capacity = df.oat_c.apply(MRC)\n",
    "    \n",
    "    crs_kwth = df.CRS_Load_values*df.oat_c.apply(Isentropic_eff)\n",
    "    \n",
    "    remaining_crs_kwth = total_rack_capacity - crs_kwth\n",
    "    \n",
    "    chg_limit_kwth = [min(x,MCL) for x in remaining_crs_kwth]\n",
    "    cop_chg_rt1 = df.oat_c.apply(CHG_COP_rt1)\n",
    "    \n",
    "    chg_limit = chg_limit_kwth/cop_chg_rt1\n",
    "\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    # Calculate Discharge limits:\n",
    "    \n",
    "    # Sensible subcool fit:\n",
    "    sens_subcool_func = lambda t:  0.01364*t*t - 0.4733*t + 3.973\n",
    "    \n",
    "    subcool_offset = df.oat_c.apply(sens_subcool_func)\n",
    "    \n",
    "    if sensible_subcool :\n",
    "        dchg_limit = data['CRS_Load_values'] + subcool_offset\n",
    "    else:\n",
    "        dchg_limit = data['CRS_Load_values']\n",
    "        \n",
    "    df['charge_limits'] = chg_limit\n",
    "    df['discharge_limits'] = dchg_limit\n",
    "    \n",
    "    return dict(zip(time_labels, chg_limit)), dict(zip(time_labels, dchg_limit)), df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_COPs(data, start_ts, end_ts, time_labels, sens_subcool):\n",
    "\n",
    "    \n",
    "    # For RT = 1 (HTF pump power of 3.5kWe at 170 gpm)\n",
    "    CHG_COP_rt_10 = lambda t: 0.00011286509783997348*t*t -0.02835906022493903*t + 2.0938080794453984\n",
    "    \n",
    "    CHG_COP_rt_05 = lambda t: 0.0011778033118712684*t*t -0.15557305693781495*t + 2.235440437544005\n",
    "    \n",
    "    COP_chg_func = CHG_COP_rt_10\n",
    "\n",
    "    if sens_subcool:\n",
    "        COP_dchg_func = lambda t: 0.001091*t*t - 0.155*t + 6.359\n",
    "    else:\n",
    "        COP_dchg_func = lambda t: 0.0011778033118712684*t*t -0.15557305693781495*t + 6.632059210693061\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if (no_of_tanks==3):\n",
    "        COP_chg_func = lambda t: -0.0000197*t*t - 0.0259*t + 2.298 # 3 PCES Tanks 19a\n",
    "    elif (no_of_tanks==4):\n",
    "        COP_chg_func = lambda t: -0.0000188*t*t - 0.0261*t + 2.308 # 4 PCES Tanks 19b\n",
    "    elif (no_of_tanks==5):\n",
    "        COP_chg_func = lambda t: -0.0000184*t*t - 0.02619*t + 2.313 # 5 PCES Tanks 19c\n",
    "    elif (no_of_tanks==6):\n",
    "        COP_chg_func = lambda t: -0.0000181*t*t - 0.02624*t + 2.315 # 6 PCES Tanks 19d\n",
    "    \n",
    "    #COP_chg_func = lambda t: 0.0001403*t*t - 0.03362*t + 2.346\n",
    "    #COP_chg_func = lambda t: 0.0002245*t*t - 0.04221*t + 2.69\n",
    "    \"\"\"\n",
    "    \n",
    "    Timestamp_labels = Timestamp_label_generator(start_ts,end_ts, timezone)\n",
    "    \n",
    "    COP_df = Timestamp_labels.merge(data, on= 'Timestamp') \n",
    "    \n",
    "    COP_df = COP_df.assign(oat_c = COP_df.temperature.apply(lambda d: (d - 32)*5/9))\n",
    "\n",
    "    COP_df = COP_df.assign(COP_dchg = COP_df.oat_c.apply(COP_dchg_func))\n",
    "    COP_df = COP_df.assign(COP_chg = COP_df.oat_c.apply(COP_chg_func))\n",
    "    \n",
    "    Dchg_dict = dict(zip(time_labels,COP_df.COP_dchg))\n",
    "    Chg_dict = dict(zip(time_labels,COP_df.COP_chg))\n",
    "    \n",
    "    return (Dchg_dict,Chg_dict, COP_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_loads(Load_table, event_days):\n",
    "    \n",
    "    event_loads = []\n",
    "    \n",
    "    for ts in Load_table.Timestamp:\n",
    "        if ts.date() in event_days:\n",
    "            if (datetime.time(hour =  ts.hour) >= datetime.time(hour = 14) and \n",
    "                datetime.time(hour =  ts.hour) < datetime.time(hour = 18)):\n",
    "                event_loads.append(Load_table.loc[Load_table.Timestamp == ts]['Load_values'].iloc[0])\n",
    "    \n",
    "    return event_loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bill_calculator(Load, Tariff, Max_demands, cap_res, cap_res_rate, cpp_addr, event_loads, days):\n",
    "\n",
    "    summer_days = days[0]\n",
    "    winter_days = days[1]\n",
    "    total_days = summer_days + winter_days\n",
    "    surcharge_rate = 0.000300\n",
    "    regulatory_rate = 0.000580\n",
    "    \n",
    "    Demand_charges = Demand_charges_generator()\n",
    "    \n",
    "    Energy_bill = sum([a*b/4 for a,b in zip(Load, Tariff)])\n",
    "    \n",
    "    if summer_days != 0:\n",
    "        Demand_bill_summer = (Max_demands['Maximum_Demand_Summer']*Demand_charges['Maximum Demand Summer']+\n",
    "                          Max_demands['Maximum_Peak_Demand_Summer']*Demand_charges['Maximum Peak Demand Summer'])\n",
    "    else :\n",
    "        Demand_bill_summer = 0\n",
    "\n",
    "    if winter_days != 0:\n",
    "        Demand_bill_winter = (Max_demands['Maximum_Demand_Winter']*Demand_charges['Maximum Demand Winter']+\n",
    "                         Max_demands['Maximum_Peak_Demand_Winter']*Demand_charges['Maximum Peak Demand Winter'])\n",
    "        \n",
    "    else :\n",
    "        Demand_bill_winter = 0\n",
    "\n",
    "    Demand_bill = Demand_bill_summer*summer_days/total_days + Demand_bill_winter*winter_days/total_days\n",
    "    \n",
    "    CPP_event_cost = sum([0.25*(load - cap_res)*cpp_addr for load in event_loads])\n",
    "        \n",
    "    CPP_fixed = cap_res*cap_res_rate\n",
    "    \n",
    "    CPP_bill =  CPP_fixed + CPP_event_cost\n",
    "    \n",
    "    Energy_consumed = sum(Load)/4\n",
    "    \n",
    "    Taxes = Energy_consumed*surcharge_rate + Energy_consumed*regulatory_rate\n",
    "    \n",
    "    return (Energy_bill, Demand_bill, CPP_bill, Taxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heatleak(df):\n",
    "    \n",
    "    heat_leak_fit = lambda t : 1.620034306572543e-06*t*t + 0.055326591739501836*t + 1.4352336893428248\n",
    "    \n",
    "    df = df.assign(heatleak = df.oat_c.apply(heat_leak_fit))\n",
    "    \n",
    "    return dict(zip(time_labels, df.heatleak))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dchg_cop, chg_cop):\n",
    "    \n",
    "    SOC = LpVariable.dicts(\"SOC\", time_labels, lowBound = 0, upBound = RB_capacity)\n",
    "\n",
    "    dof = LpVariable.dicts(\"Discharge_Offset\", time_labels, lowBound = 0 , upBound = None)\n",
    "\n",
    "    cof = LpVariable.dicts(\"Charge_Offset\", time_labels, lowBound = 0 , upBound = None)\n",
    "\n",
    "    y = LpVariable.dicts(\"Selector\", time_labels, lowBound = None , upBound = None, cat = 'Binary')\n",
    "\n",
    "    Max_peak_Summer = LpVariable(\"Maximum Peak Demand Summer\", lowBound = 0, upBound = None)\n",
    "    Max_Summer = LpVariable(\"Maximum Demand Summer\", lowBound = 0, upBound = None)\n",
    "\n",
    "    Max_peak_Winter = LpVariable(\"Maximum Peak Demand Winter\", lowBound = 0, upBound = None)\n",
    "    Max_Winter = LpVariable(\"Maximum Demand Winter\", lowBound = 0, upBound = None)\n",
    "\n",
    "    E = LpVariable.dict(\"Event_intervals\", event_labels, lowBound=0, upBound= None)\n",
    "\n",
    "    prob = LpProblem(\"Simple schedule optimization\",LpMinimize)\n",
    "\n",
    "    #### Defining Objective function\n",
    "\n",
    "    Energy_portion = [Energy_Tariff[t]*(0.25*Building_Power[t] - 0.25*(dof[t] - cof[t])) for t in time_labels]\n",
    "    Demand_portion = [Max_peak_Summer*Demand_charges['Maximum Peak Demand Summer'] +\n",
    "                      Max_Summer*Demand_charges['Maximum Demand Summer'] + \n",
    "                      Max_peak_Winter*Demand_charges['Maximum Peak Demand Winter'] +\n",
    "                      Max_Winter*Demand_charges['Maximum Demand Winter']]\n",
    "    CPP_portion = [E[e]*CPP_adder for e in event_labels]\n",
    "\n",
    "    prob+=lpSum(Energy_portion + Demand_portion + CPP_portion)\n",
    "\n",
    "\n",
    "    #### Defining constraints\n",
    "\n",
    "    count = 0\n",
    "    event_ts_labels = []\n",
    "\n",
    "    for t in range(0,len(time_labels)):\n",
    "\n",
    "        if (t < len(time_labels)-1):\n",
    "            soc_difference = (SOC[time_labels[t]] - SOC[time_labels[t+1]])\n",
    "\n",
    "            effective_energy = 0.25 * (dchg_cop[time_labels[t]]*dof[time_labels[t]] - chg_cop[time_labels[t]]*cof[time_labels[t]]) \n",
    "\n",
    "            heat_leak_value = 0.25*heat_leak[time_labels[t]]  \n",
    "                \n",
    "            prob+= soc_difference == effective_energy + heat_leak_value\n",
    "\n",
    "        prob+= cof[time_labels[t]] <= chg_limits[time_labels[t]]\n",
    "\n",
    "        prob+= dof[time_labels[t]] <= dchg_limits[time_labels[t]]\n",
    "\n",
    "        prob+= dof[time_labels[t]] <= M*y[time_labels[t]]\n",
    "\n",
    "        prob+= cof[time_labels[t]] <= M*(1-y[time_labels[t]])\n",
    "\n",
    "        # Adding constraints for event days\n",
    "        ts = Timestamp_labels[time_labels[t]]\n",
    "\n",
    "        if ts.date() in event_days:\n",
    "\n",
    "\n",
    "            if (datetime.time(hour =  ts.hour) >= datetime.time(hour = 14) and \n",
    "                datetime.time(hour =  ts.hour) < datetime.time(hour = 18)):\n",
    "\n",
    "                prob+=  E[event_labels[count]] == 0.25*(Building_Power[time_labels[t]] - Cap_res\n",
    "                                                        - dof[time_labels[t]] + cof[time_labels[t]])\n",
    "                count+=1\n",
    "\n",
    "            else:\n",
    "\n",
    "                event_ts_labels.append(time_labels[t])\n",
    "\n",
    "        if (Season(ts) == 'Summer'):\n",
    "\n",
    "            if time_labels[t] not in event_ts_labels: \n",
    "\n",
    "                prob+= Max_Summer>= Building_Power[time_labels[t]] - (dof[time_labels[t]] - cof[time_labels[t]])\n",
    "\n",
    "            if Period(Timestamp_labels[time_labels[t]], Holidays) == 'On-Peak Summer':\n",
    "\n",
    "                prob+= Max_peak_Summer>= Building_Power[time_labels[t]] - (dof[time_labels[t]] - cof[time_labels[t]])\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            if time_labels[t] not in event_ts_labels:\n",
    "\n",
    "                prob+= Max_Winter>= Building_Power[time_labels[t]] - (dof[time_labels[t]] - cof[time_labels[t]])\n",
    "\n",
    "            if Period(Timestamp_labels[time_labels[t]], Holidays) == 'On-Peak Winter':\n",
    "\n",
    "                prob+= Max_peak_Winter>= Building_Power[time_labels[t]] - (dof[time_labels[t]] - cof[time_labels[t]])\n",
    "\n",
    "\n",
    "        # Additional bounding constraint on discharge offset as f(SOC)\n",
    "\n",
    "        fac_decrease = dchg_cop[time_labels[t]]\n",
    "\n",
    "        for pair in mc_list:\n",
    "            prob+= dof[time_labels[t]] <= (pair[0]*SOC[time_labels[t]] + pair[1])/fac_decrease\n",
    "\n",
    "\n",
    "    # Adding constraints for initial & final condition (SOC)\n",
    "\n",
    "    prob+=SOC[\"T01\"] == SOC_initial\n",
    "    prob+=SOC[time_labels.iloc[-1]] == SOC_final\n",
    "\n",
    "    #### Past peak target setting\n",
    "\n",
    "    \"\"\"\n",
    "    if season == \"Summer\":\n",
    "        prob+= Max_peak_Summer >= on_peak\n",
    "        prob+= Max_Summer >= non_coincidental\n",
    "\n",
    "        prob+= Max_Summer >= Max_peak_Summer\n",
    "\n",
    "    else:\n",
    "        prob+= Max_peak_Winter >= on_peak\n",
    "        prob+= Max_Winter >= non_coincidental\n",
    "\n",
    "        prob+= Max_Winter >= Max_peak_Winter\n",
    "    \"\"\"\n",
    "\n",
    "    lpFileName= \"batteryOperation.lp\"\n",
    "    prob.writeLP(lpFileName)\n",
    "\n",
    "    LpSolverDefault.msg = 1\n",
    "\n",
    "    prob.solve()\n",
    "\n",
    "    ## SEE STATUS OF OPTIMIZATION SOLUTION HERE:\n",
    "\n",
    "    # print status\n",
    "    print(\"Status:\", LpStatus[prob.status])\n",
    "\n",
    "    discharge_offsets = {}\n",
    "    charge_offsets = {} \n",
    "    charge_states = {}\n",
    "    selector = {}\n",
    "    Event_interval_excess = {}\n",
    "    Max_demands_newload = {}\n",
    "\n",
    "    for v in prob.variables():\n",
    "\n",
    "        if (v.name[0:9] == 'Discharge'):\n",
    "            discharge_offsets[v.name] = v.varValue\n",
    "\n",
    "        elif (v.name[0:6] == 'Charge'):\n",
    "            charge_offsets[v.name] = v.varValue\n",
    "\n",
    "        elif(v.name[0:3] == 'SOC'):\n",
    "            charge_states[v.name] = v.varValue\n",
    "\n",
    "        elif(v.name[0:8] == 'Selector'):\n",
    "            selector[v.name] = v.varValue\n",
    "\n",
    "        elif(v.name[0:5] == \"Event\"):\n",
    "            Event_interval_excess[v.name] = v.varValue\n",
    "\n",
    "        else:\n",
    "            Max_demands_newload[v.name] = v.varValue\n",
    "\n",
    "    offset_dchg = []\n",
    "    offset_chg = []\n",
    "    offset_values = []\n",
    "    charge_values = []\n",
    "    crs_load = []\n",
    "    Max_charge_values = []\n",
    "    Max_discharge_values = []\n",
    "    charge_cop_list = []\n",
    "    discharge_cop_list = []\n",
    "    heat_leak_list = []\n",
    "\n",
    "    for i in range(1,len(time_labels)+1):\n",
    "        offset_dchg.append(discharge_offsets[\"Discharge_Offset_T\"+str(i).zfill(2)])\n",
    "        offset_chg.append(-charge_offsets[\"Charge_Offset_T\"+str(i).zfill(2)])         \n",
    "        offset_values.append(discharge_offsets[\"Discharge_Offset_T\"+str(i).zfill(2)] - charge_offsets[\"Charge_Offset_T\"+str(i).zfill(2)])\n",
    "        charge_values.append(charge_states[\"SOC_T\"+str(i).zfill(2)])\n",
    "        crs_load.append(CRS_dict[time_labels[i-1]])\n",
    "        Max_charge_values.append(-chg_limits[time_labels[i-1]])\n",
    "        Max_discharge_values.append(dchg_limits[time_labels[i-1]])\n",
    "        charge_cop_list.append(chg_cop[time_labels[i-1]])\n",
    "        discharge_cop_list.append(dchg_cop[time_labels[i-1]])\n",
    "        heat_leak_list.append(heat_leak[time_labels[i-1]])\n",
    "        \n",
    "\n",
    "    new_Load_values = [a - b for a,b in zip(Load_values,offset_values)]\n",
    "\n",
    "    new_Load_table = Load_table.assign(Load_values = new_Load_values)\n",
    "\n",
    "    # Threshold & Savings Results\n",
    "\n",
    "    event_loads = get_event_loads(Load_table, event_days)\n",
    "    new_event_loads = get_event_loads(new_Load_table, event_days)\n",
    "    \n",
    "    output = pd.DataFrame({'Timelabels': time_labels,\n",
    "                          'Discharge_offset':offset_dchg,\n",
    "                          'Charge_offset':offset_chg,\n",
    "                          'Offset':offset_values,\n",
    "                          'Timestamps': Tariff_table.Timestamp,\n",
    "                          'State_of_charge':charge_values,\n",
    "                          'Max_charge_limit': Max_charge_values, \n",
    "                          'Max_discharge_limit': Max_discharge_values,\n",
    "                          'Baseline': Load_values,\n",
    "                          'Target': new_Load_values,\n",
    "                          'Temperature' : COP_df.temperature,\n",
    "                          'COP_discharge':discharge_cop_list,\n",
    "                          'COP_charge': charge_cop_list,\n",
    "                          'CRS_load' : crs_load,\n",
    "                          'Heat_leak': heat_leak_list\n",
    "                         })\n",
    "    \n",
    "    [old_energybill, old_demandbill, old_cpp_bill, old_tax] = Bill_calculator(Load_values, Tariff_list, Max_demands_load, \n",
    "                                                       Cap_res, Cap_res_rate, CPP_adder, event_loads, day_split)\n",
    "    [new_energybill, new_demandbill, new_cpp_bill, new_tax] = Bill_calculator(new_Load_values, Tariff_list,Max_demands_newload,\n",
    "                                                       Cap_res, Cap_res_rate, CPP_adder, new_event_loads, day_split)\n",
    "    \n",
    "    # Adding Reactive Control Buffer\n",
    "    \n",
    "    Max_demands_adj = {k:v + RCB for k,v in Max_demands_newload.items()}\n",
    "    \n",
    "    [adj_energybill, adj_demandbill, adj_cpp_bil, adj_tax] = Bill_calculator(new_Load_values, Tariff_list,Max_demands_adj,\n",
    "                                                       Cap_res, Cap_res_rate, CPP_adder, new_event_loads, day_split) \n",
    "\n",
    "    print(\"Building baseline demand peaks are: \\n\", Max_demands_load)\n",
    "\n",
    "    print(\"Target demand peaks are: \\n\", Max_demands_newload)\n",
    "\n",
    "    demand_savings = old_demandbill - adj_demandbill\n",
    "    energy_savings = old_energybill - new_energybill\n",
    "    cpp_savings = old_cpp_bill - new_cpp_bill\n",
    "    tax_savings = old_tax - new_tax\n",
    "    total_savings = demand_savings + energy_savings + cpp_savings + tax_savings\n",
    "    \n",
    "    print(\"Ideal Demand Savings  ${}\".format(demand_savings))\n",
    "    print(\"Ideal Energy Savings  ${}\".format(energy_savings))\n",
    "    print(\"Ideal CPP Savings     ${}\".format(cpp_savings))\n",
    "    print(\"Tax savings           ${}\".format(tax_savings))\n",
    "    print(\"Ideal Total Savings   ${}\".format(total_savings))\n",
    "\n",
    "    return output, demand_savings, energy_savings, cpp_savings, tax_savings, total_savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(p1, p2):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "\n",
    "    m = (y2 - y1) / (x2 - x1)\n",
    "    b = y1 - m * x1\n",
    "    return lambda x: m*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_updated_cop(df):\n",
    "    \n",
    "    CHG_COP_rt_10 = lambda t: 0.00011286509783997348*t*t -0.02835906022493903*t + 2.0938080794453984\n",
    "    \n",
    "    CHG_COP_rt_05 = lambda t: 0.0011778033118712684*t*t -0.15557305693781495*t + 2.235440437544005\n",
    "    \n",
    "    df = df.assign(temperature = df.Temperature.apply(lambda d: (d - 32)*5/9))\n",
    "    \n",
    "    chg_offset_kwth = -df.Charge_offset * df.COP_charge\n",
    "    \n",
    "    # Get interpolated RT from charge offset kwth\n",
    "    min_rt = 0.5/3\n",
    "    max_rt = 1.0\n",
    "    \n",
    "    rt_line = line((SI_MCL_lower, min_rt),(SI_MCL_upper, max_rt))\n",
    "    rt = rt_line(chg_offset_kwth)\n",
    "    \n",
    "    rt.loc[rt<min_rt]=min_rt\n",
    "    \n",
    "    # Get interpolated CHG COP\n",
    "    min_cops = df.temperature.apply(CHG_COP_rt_05)\n",
    "    max_cops = df.temperature.apply(CHG_COP_rt_10)\n",
    "    \n",
    "    cop_lines = line((min_rt, min_cops),(max_rt, max_cops))\n",
    "    \n",
    "    chg_cop = cop_lines(rt)\n",
    "    \n",
    "    return dict(zip(time_labels, chg_cop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions: Give path to perfest & weather files below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_file = \"WMEC_2017_baselines_March_Oct.pickle\" #WMEC_2017_baselines_March_Oct       2018_11_01_to_2019_06_02_perfest\n",
    "temperature_data_file = \"WMEC_2017_temperature_March_Oct.pickle\"#WMEC_2017_temperature_March_Oct     2018_11_01_to_2019_06_02_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(load_data_file, 'rb') as fp:\n",
    "    perf_data = pickle.load(fp)\n",
    "    \n",
    "with open(temperature_data_file, 'rb') as tp:\n",
    "    temp_data = pickle.load(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPAC = pytz.timezone('US/Pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(perf_data, dict) & isinstance(temp_data, dict):\n",
    "    \n",
    "    perf_df = pd.DataFrame(perf_data['values'], columns = perf_data['columns'])\n",
    "    perf_df.time = perf_df.time.apply(lambda d: pytool.time.fromutctimestamp(d/1000000))\n",
    "    perf_df.time = perf_df.time.apply(lambda d: d.astimezone(USPAC))\n",
    "    perf_df = perf_df.set_index('time', drop=True)\n",
    "    perf_df = perf_df.resample('15T').mean()\n",
    "    \n",
    "    tdf = pd.DataFrame(temp_data['values'], columns =  temp_data['columns'])\n",
    "    tdf.time = tdf.time.apply(lambda d: pytool.time.fromutctimestamp(d/1000000))\n",
    "    tdf.time = tdf.time.apply(lambda d: d.astimezone(USPAC))\n",
    "    tdf = tdf.set_index('time', drop=True)\n",
    "    tdf = tdf.resample('15T').mean()\n",
    "    \n",
    "else:\n",
    "    perf_df = perf_data\n",
    "    d = perf_df.time.iloc[0]\n",
    "    if d.tzinfo is None:\n",
    "        perf_df.time = perf_df.time.apply(lambda d: USPAC.localize(d))\n",
    "    perf_df = perf_df.set_index('time', drop=True)\n",
    "    tdf = temp_data\n",
    "    t = tdf.time.iloc[0]\n",
    "    if t.tzinfo is None:    \n",
    "        tdf.time = tdf.time.apply(lambda d: USPAC.localize(d))\n",
    "    tdf = tdf.set_index('time', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = perf_df.assign(Timestamp = perf_df.index)\n",
    "tdf = tdf.assign(Timestamp = tdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = perf_df.reset_index(drop=True)\n",
    "tdf = tdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = tdf[['temperature','Timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tdf.head(5)\n",
    "#perf_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23520"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(perf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23520"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set RB CAPACITY & SLOPE-INTERCEPT VALUES HERE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration for - 20\n",
    "#configuration = {3:(1300,[(1.274433,2.959688),(0.336134,36.103594),(0.179726,72.055120),(0.043531,129.503864),(0.080557,86.631784)]),\n",
    "               #  4:(1994,[(6.661962,1.140559),(0.680812,20.741421),(0.287804,46.541683),(0.141617,91.239041),(0.030589,158.985901),(0.679740,-1078.868280)]),\n",
    "                # 5:(2475,[(0.884465,7.121315),(0.282327,48.687316),(0.142177,93.556521),(0.079878,130.156775),(0.020400,182.391462),(0.524228,-1019.933002)]), \n",
    "                 #6:(2955,[(1.031328,8.097714),(0.276624,53.611903),(0.135329,98.482125),(0.068889,140.393125),(0.015271,198.184738),(0.542011,-1313.734919)])}\n",
    "#This is the update configuration for 3,4, and 5 tanks. We might have to remove the last term that is being linearized since this might create an over constrain in the problem\n",
    "\n",
    "configuration = {3:(1391,[(20.798406,6.510438),(1.179376,30.423908),(0.151886,97.356370),(0.038226,138.415064),(0.116077,47.640328)]),\n",
    "                 4:(1854,[(29.831810,7.345354),(0.390607,55.583742),(0.164344,101.413539),(0.025810,170.186787),(0.102405,44.464230)]),\n",
    "                5:(2319,[(118.574931,7.184441),(1.585666,43.248301),(0.075239,118.931145),(0.165486,101.703185),(0.021718,186.597549)]), \n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET NO OF TANKS HERE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_tanks = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Start & End date & other optimization parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define start and end periods\n",
    "start_date = pd.to_datetime('2017-7-1 00:00:00')\n",
    "end_date = pd.to_datetime('2017-7-31 23:45:00')#14:45:00 23:45\n",
    "timezone = USPAC\n",
    "#define tuning parameters value\n",
    "\n",
    "SI_MCL_upper = 91.61            # CMP RT 1.0 in kWt 91.61 wmec specific\n",
    "SI_MCL_lower = 18.32            # CMP RT 0.5/3 kWt 18.32\n",
    "MDCR =  1000                     # Max discharge rate\n",
    "SOC_initial = 1855           # Initial state of charge\n",
    "SOC_final = SOC_initial\n",
    "RB_capacity = configuration[no_of_tanks][0]            # Thermal Tank\n",
    "M = 10000                       # Large M value for using big M method\n",
    "billing_window = 30\n",
    "sensible_subcool = True\n",
    "RCB = 0                        #Reactive Control Buffer; 0 means no reactive control buffer\n",
    "derating_factor_energy = 0.95      # Derating factor for energy (read as \"derate to\") : 1 means no derating\n",
    "derating_factor_demand = 0.85      # Derating factor for demand (read as \"derate to\") : 1 means no derating\n",
    "\n",
    "### CPP related configuration parameters\n",
    "\n",
    "Cap_res = 159.7        # in KW don't really need to change since it has been set with SDG&E part of the CPP rate plan\n",
    "CPP_adder = 1.88        # in $/kWh set according to tariff document\n",
    "Cap_res_rate = 4.68    # in $/kW per month set according to tariff document WMEC specific\n",
    "event_days = [datetime.date(2017, 7, 6),#8 Sep\n",
    "              datetime.date(2017, 7, 24),#9 Sep\n",
    "              datetime.date(2017, 7, 25)]#14 Sep\n",
    "               # datetime.date(2018, 9, 13),#14 Sep\n",
    "              # datetime.date(2018, 9, 27)\n",
    "             #]\n",
    "#event_days = []        # no CPP turn on and off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_labels = Event_label_generator(len(event_days))\n",
    "mc_list = configuration[no_of_tanks][1]\n",
    "no_of_days = (end_date - start_date).days\n",
    "Holidays = Holidays_generator()\n",
    "tf = no_of_days/billing_window\n",
    "\n",
    "tsdf = Timestamp_label_generator(start_date,end_date, timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_df = tsdf.merge(tdf, on  ='Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = mid_df.merge(perf_df, on = 'Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.index = final_df.Timestamp\n",
    "#final_df = final_df.interpolate(method = 'bfill')\n",
    "final_df = final_df.fillna(method = 'bfill')\n",
    "\n",
    "final_df = final_df[~final_df.duplicated(subset = 'Timestamp', keep = 'first')]\n",
    "final_df = final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ADD TEMPERATURE FLOOR\n",
    "final_df.temperature = final_df.temperature.apply(lambda d: 57 if d<57 else d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time_label</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>temperature</th>\n",
       "      <th>building.baseline.power.kW</th>\n",
       "      <th>crs.baseline.power.kW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Time_label, Timestamp, temperature, building.baseline.power.kW, crs.baseline.power.kW]\n",
       "Index: []"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df[\"crs.baseline.power.kW\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.columns\n",
    "Demand_charges = Demand_charges_generator()\n",
    "[Load_table,Max_demands_load] = Load_generator(final_df,start_date,end_date, timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summer_days = len(Load_table[Load_table.Seasons == 'Summer']) if \"Summer\" in list(Load_table.Seasons) else 0\n",
    "Winter_days = len(Load_table[Load_table.Seasons == 'Winter']) if \"Winter\" in list(Load_table.Seasons) else 0\n",
    "day_split = (Summer_days, Winter_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Update start & end dates based on available data in the Load table\n",
    "start_date = Load_table.Timestamp.iloc[0]\n",
    "end_date = Load_table.Timestamp.iloc[-1]\n",
    "Tariff_table = Tariff_generator(start_date, end_date, timezone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Energy_Tariff = dict(zip(Tariff_table.Time_label,Tariff_table.energy_tariff))\n",
    "Building_Power = dict(zip(Load_table.Time_label,Load_table.Load_values))\n",
    "\n",
    "Load_values = Load_table.Load_values\n",
    "Tariff_list = Tariff_table.energy_tariff\n",
    "\n",
    "Timestamp_labels = dict(zip(Tariff_table.Time_label,Tariff_table.Timestamp))\n",
    "\n",
    "time_labels = Tariff_table.Time_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRS_dict, CRS_Load = CRS_load(final_df, start_date, end_date, time_labels, timezone)\n",
    "\n",
    "[dchg_cop, chg_cop, COP_df] = get_COPs(final_df, start_date, end_date, time_labels, sensible_subcool)\n",
    "\n",
    "chg_limits, dchg_limits, limits_df = get_Limits(CRS_Load, SI_MCL_upper, sensible_subcool)\n",
    "\n",
    "heat_leak = get_heatleak(COP_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN ITERATIVE LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Optimal\n",
      "Building baseline demand peaks are: \n",
      " {'Maximum_Peak_Demand_Summer': 263.68, 'Maximum_Demand_Summer': 270.08}\n",
      "Target demand peaks are: \n",
      " {'Maximum_Demand_Summer': 222.42733, 'Maximum_Demand_Winter': 0.0, 'Maximum_Peak_Demand_Summer': 222.42733, 'Maximum_Peak_Demand_Winter': 0.0}\n",
      "Ideal Demand Savings  $1873.2457054999995\n",
      "Ideal Energy Savings  $-294.3982498514597\n",
      "Ideal CPP Savings     $1328.7825105699999\n",
      "Tax savings           $-3.309704631389195\n",
      "Ideal Total Savings   $2904.3202615871505\n",
      "Status: Optimal\n",
      "Building baseline demand peaks are: \n",
      " {'Maximum_Peak_Demand_Summer': 263.68, 'Maximum_Demand_Summer': 270.08}\n",
      "Target demand peaks are: \n",
      " {'Maximum_Demand_Summer': 227.65229, 'Maximum_Demand_Winter': 0.0, 'Maximum_Peak_Demand_Summer': 226.56, 'Maximum_Peak_Demand_Winter': 0.0}\n",
      "Ideal Demand Savings  $1674.6538132999995\n",
      "Ideal Energy Savings  $-303.06784264316593\n",
      "Ideal CPP Savings     $1328.7825105699999\n",
      "Tax savings           $-3.229989294929709\n",
      "Ideal Total Savings   $2697.138491931904\n",
      "Status: Optimal\n",
      "Building baseline demand peaks are: \n",
      " {'Maximum_Peak_Demand_Summer': 263.68, 'Maximum_Demand_Summer': 270.08}\n",
      "Target demand peaks are: \n",
      " {'Maximum_Demand_Summer': 232.76815, 'Maximum_Demand_Winter': 0.0, 'Maximum_Peak_Demand_Summer': 230.4, 'Maximum_Peak_Demand_Winter': 0.0}\n",
      "Ideal Demand Savings  $1483.8037255\n",
      "Ideal Energy Savings  $-275.0047288220703\n",
      "Ideal CPP Savings     $1328.7825105699999\n",
      "Tax savings           $-2.8670319113293488\n",
      "Ideal Total Savings   $2534.7144753366\n",
      "Status: Optimal\n",
      "Building baseline demand peaks are: \n",
      " {'Maximum_Peak_Demand_Summer': 263.68, 'Maximum_Demand_Summer': 270.08}\n",
      "Target demand peaks are: \n",
      " {'Maximum_Demand_Summer': 238.08, 'Maximum_Demand_Winter': 0.0, 'Maximum_Peak_Demand_Summer': 232.96, 'Maximum_Peak_Demand_Winter': 0.0}\n",
      "Ideal Demand Savings  $1310.5023999999994\n",
      "Ideal Energy Savings  $-237.31281209744702\n",
      "Ideal CPP Savings     $1298.236959449\n",
      "Tax savings           $-2.451792178505798\n",
      "Ideal Total Savings   $2368.9747551730466\n",
      "Status: Optimal\n",
      "Building baseline demand peaks are: \n",
      " {'Maximum_Peak_Demand_Summer': 263.68, 'Maximum_Demand_Summer': 270.08}\n",
      "Target demand peaks are: \n",
      " {'Maximum_Demand_Summer': 239.36, 'Maximum_Demand_Winter': 0.0, 'Maximum_Peak_Demand_Summer': 233.6, 'Maximum_Peak_Demand_Winter': 0.0}\n",
      "Ideal Demand Savings  $1268.3392000000003\n",
      "Ideal Energy Savings  $-214.2570444641533\n",
      "Ideal CPP Savings     $1183.0437022\n",
      "Tax savings           $-2.2094650038993677\n",
      "Ideal Total Savings   $2234.916392731948\n"
     ]
    }
   ],
   "source": [
    "previous_total_savings = 0\n",
    "prev_diff = 0\n",
    "count = 1\n",
    "\n",
    "while True:\n",
    "\n",
    "    output, demand_savings, energy_savings, cpp_savings, tax_savings, total_savings = evaluate(dchg_cop, chg_cop)\n",
    "    \n",
    "    diff = abs(previous_total_savings - total_savings)\n",
    "    \n",
    "    if diff < 10 or count == 5 or abs(diff - prev_diff) < 1:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    previous_total_savings = total_savings\n",
    "    prev_diff = diff\n",
    "    chg_cop = get_updated_cop(output)\n",
    "    \n",
    "    count+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Demand Savings  $1268.3392000000003\n",
      "Ideal Energy Savings  $-214.2570444641533\n",
      "Ideal CPP Savings     $1183.0437022\n",
      "Tax savings           $-2.2094650038993677\n",
      "Ideal Total Savings   $2237.125857735847\n",
      "134.05836244109878\n"
     ]
    }
   ],
   "source": [
    "print(\"Ideal Demand Savings  ${}\".format(demand_savings))\n",
    "print(\"Ideal Energy Savings  ${}\".format(energy_savings))\n",
    "print(\"Ideal CPP Savings     ${}\".format(cpp_savings))\n",
    "print(\"Tax savings           ${}\".format(tax_savings))\n",
    "print(\"Ideal Total Savings   ${}\".format(demand_savings + energy_savings + cpp_savings))\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derated Demand Savings  $1078.0883200000003\n",
      "Ideal Energy Savings  $-203.54419224094562\n",
      "Ideal CPP Savings     $1183.0437022\n",
      "Tax savings           $-2.2094650038993677\n",
      "Ideal Total Savings   $2057.587829959055\n"
     ]
    }
   ],
   "source": [
    "# Derated savings (Will be the same as Ideal savings if derating factors are set to 1)\n",
    "print(\"Derated Demand Savings  ${}\".format(demand_savings*derating_factor_demand))\n",
    "print(\"Ideal Energy Savings  ${}\".format(energy_savings*derating_factor_energy))\n",
    "print(\"Ideal CPP Savings     ${}\".format(cpp_savings))\n",
    "print(\"Tax savings           ${}\".format(tax_savings))\n",
    "print(\"Ideal Total Savings   ${}\".format(demand_savings*derating_factor_demand + \n",
    "                                         energy_savings*derating_factor_energy + \n",
    "                                         cpp_savings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = list(map(lambda d: str(d.month) + '/'+ str(d.day) + ' : ' + str(d.hour) + 'H',\n",
    "              [start_date + datetime.timedelta(hours = 4*i) for i in range(6*no_of_days)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Baselines, targets, offsets, SOC & limits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (20,10))\n",
    "plt.title(title, fontsize = 18)\n",
    "\n",
    "#plotting power related graphs on first y axis\n",
    "ln1 = ax.plot(output.Timestamps[476:960], output.Offset[476:960], label = \"Offset\");\n",
    "ln2 = ax.plot(output.Timestamps[476:960], output.Baseline[476:960], label = 'Building Power');\n",
    "ln3 = ax.plot(output.Timestamps[476:960], output.Target[476:960], label = 'New Building Power');\n",
    "ln4 = ax.plot(output.Timestamps[476:960], output.Max_charge_limit[476:960], label = 'Max Charge Values');\n",
    "ln5 = ax.plot(output.Timestamps[476:960], output.Max_discharge_limit[476:960], label = 'Max Discharge Values');\n",
    "ln7 = ax.plot(output.Timestamps[476:960], output.Temperature[476:960], label = 'Temperature');\n",
    "\n",
    "ax.set_xlabel('Time period')\n",
    "ax.set_ylabel('Power in KW')\n",
    "\n",
    "start, end = ax.get_xlim();\n",
    "#ax.set_xticks(np.arange(start, end, 8))\n",
    "#ax.set_xticklabels(sv)\n",
    "#plt.xticks(np.arange(start+33.55, end+33.55, 16), sv, rotation=90);\n",
    "\n",
    "#creating second y axis and plotting SOC\n",
    "ax2 = ax.twinx();\n",
    "ln6 = ax2.plot(output.Timestamps[476:960], output.State_of_charge[476:960], '--',label = \"SOC\");\n",
    "\n",
    "ax2.set_ylabel('State of charge in KWhe')\n",
    "\n",
    "ax.axhline(0, color = 'black');\n",
    "ax.axhline(Cap_res, color = 'magenta');\n",
    "#Managing labels and legend\n",
    "lns = ln1 + ln2 + ln3 + ln4 + ln5 + ln7\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax.legend(lns, labs, loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = pd.DataFrame(columns = [\"MCR\",\"Tank_Capacity\",\"Demand_savings\",\"Energy_savings\",\"Total_savings\",\"RTE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suptitle = \"Cumulative distribution of discharge offset\"\n",
    "plt.figure(figsize = (10,6));\n",
    "plt.suptitle(suptitle, fontsize = 22);\n",
    "plt.title(title, fontsize = 11);\n",
    "plt.hist(output.Discharge_offset, bins = 100, normed = True, cumulative = True, histtype = 'step', color = 'red');\n",
    "plt.xlabel('Discharge offset range (KWhe)', fontsize = 14);\n",
    "plt.ylabel('Probability',fontsize = 14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Heat_loads = [a*b for a,b in zip(output.COP_discharge, output.Discharge_offset)]\n",
    "normalized_SOC = [x/RB_capacity for x in output.State_of_charge]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suptitle = \"Scatter plot: Heat load vs SOC\"\n",
    "plt.figure(figsize = (10,6));\n",
    "plt.suptitle(suptitle, fontsize = 22);\n",
    "plt.scatter(output.State_of_charge, Heat_loads, color = 'peru');\n",
    "plt.xlabel('SOC (kWh_thermal)', fontsize = 14);\n",
    "plt.ylabel('Heat load (KWh_thermal)',fontsize = 14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suptitle = \"Scatter plot: Heat load vs normalized SOC\"\n",
    "plt.figure(figsize = (10,6));\n",
    "plt.suptitle(suptitle, fontsize = 22);\n",
    "plt.scatter(normalized_SOC,Heat_loads, color = 'peru');\n",
    "plt.xlabel('Normalized SOC', fontsize = 14);\n",
    "plt.ylabel('Heat load (KWh_thermal)',fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte = sum(output.Discharge_offset)/-sum(output.Charge_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The RTE is %.2f\" %(rte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Discharge & Charge kWth & kWhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCHG_kWhe = 0.25*output.Discharge_offset.sum()\n",
    "CHG_kWhe = -0.25*output.Charge_offset.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCHG_kWhth = sum(0.25*output.Discharge_offset*output.COP_discharge)\n",
    "CHG_kWhth = -sum(0.25*output.Charge_offset*output.COP_charge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCHG_kWhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHG_kWhe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCHG_kWhth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHG_kWhth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
